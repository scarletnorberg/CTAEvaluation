[SERVICE]
    # Flush
    # =====
    # set an interval of seconds before to flush records to a destination
    flush        1

    # Daemon
    # ======
    # instruct Fluent Bit to run in foreground or background mode.
    daemon       Off

    # Log_Level
    # =========
    # Set the verbosity level of the service, values can be:
    #
    # - error
    # - warning
    # - info
    # - debug
    # - trace
    #
    # by default 'info' is set, that means it includes 'error' and 'warning'.
    log_level    info

    # Parsers File
    # ============
    # specify an optional 'Parsers' configuration file
    parsers_file parsers.conf

    # Plugins File
    # ============
    # specify an optional 'Plugins' configuration file to load external plugins.
    plugins_file plugins.conf

    # HTTP Server
    # ===========
    # Enable/Disable the built-in HTTP Server for metrics
    http_server  Off
    http_listen  0.0.0.0
    http_port    2020

    # Storage
    # =======
    # Fluent Bit can use memory and filesystem buffering based mechanisms
    #
    # - https://docs.fluentbit.io/manual/administration/buffering-and-storage
    #
    # storage metrics
    # ---------------
    # publish storage pipeline metrics in '/api/v1/storage'. The metrics are
    # exported only if the 'http_server' option is enabled.
    #
    storage.metrics on

    # storage.path
    # ------------
    # absolute file system path to store filesystem data buffers (chunks).
    #
    # storage.path /tmp/storage

    # storage.sync
    # ------------
    # configure the synchronization mode used to store the data into the
    # filesystem. It can take the values normal or full.
    #
    # storage.sync normal

    # storage.checksum
    # ----------------
    # enable the data integrity check when writing and reading data from the
    # filesystem. The storage layer uses the CRC32 algorithm.
    #
    # storage.checksum off

    # storage.backlog.mem_limit
    # -------------------------
    # if storage.path is set, Fluent Bit will look for data chunks that were
    # not delivered and are still in the storage layer, these are called
    # backlog data. This option configure a hint of maximum value of memory
    # to use when processing these records.
    #
    # storage.backlog.mem_limit 5M

[INPUT]
    #Name tail
    #Path /root/logs/cta_tapepools
    # Read interval (sec) Default: 1
    #interval_sec 1
    Name          exec
    Tag           cta_admin_tapepools
    Command       XrdSecPROTOCOL=sss XrdSecSSSKT=/etc/ctafrontend_client_sss.keytab cta-admin --json tapepool ls | sed 's/"\([0-9\.]\+\)"/\1/g'
    Interval_Sec  60
    Interval_NSec 0
    Buf_Size      8mb
    Oneshot       false
    #Parser        docker
[OUTPUT]
    #name  stdout
    #Name  file
    #File  output.txt
    #Path  /var/log/output/
    Name        kafka
    Match       cta_admin_tapepools
    Brokers     lssrv02.fnal.gov:9092
    Topics      ingest.cta.monitoring.tapepools
[INPUT]
    #Name tail
    #Path /root/logs/CTAQUESUESJobber
    #Path /root/logs/CTAQUESUESJobber
    #Path /root/logs/cta_failedrequests
    # Read interval (sec) Default: 1
    #interval_sec 1
    Name          exec
    Tag           cta_admin_failedrequeues
    Command       XrdSecPROTOCOL=sss XrdSecSSSKT=/etc/ctafrontend_client_sss.keytab cta-admin --json showqueues | sed 's/"\([0-9\.]\+\)"/\1/g '
    Interval_Sec  60
    #Interval_NSec 0
    Buf_Size      8mb
    Oneshot       false
    #Parser        docker
[OUTPUT]
    #name  stdout
    #Name  file
    #File  output.txt
    #Path  /var/log/output/
    Name        kafka
    Match       cta_admin_failedrequeues
    Brokers     lssrv02.fnal.gov:9092
    Topics      ingest.cta.monitoring.ctaqueues
[INPUT]
    #Name tail
    #Path /root/logs/cta_failedrequests
    #Path /root/logs/cta_failedrequests
    # Read interval (sec) Default: 1
    #interval_sec 1
    Name          exec
    Tag           cta_admin_failedrequests
    Command       XrdSecPROTOCOL=sss XrdSecSSSKT=/etc/ctafrontend_client_sss.keytab cta-admin --json fr ls | jq -r '.[] | [ .requester.username, .requestType ] | @tsv' | sort | uniq -c | awk '{print "cta-failedrequests,user="$2",requestType="$3" frCount="$1}'
    Interval_Sec  60
    Interval_NSec 0
    Buf_Size      8mb
    Oneshot       false
    #Parser        docker
[OUTPUT]
    #name  stdout
    #Name  file
    #File  output.txt
    #Path  /var/log/output/
    Name        kafka
    Match       cta_admin_failedrequests
    Brokers     lssrv02.fnal.gov:9092
    Topics      ingest.cta.monitoring.failedrequests
